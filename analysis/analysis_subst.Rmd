---
title: "Analysis of Substitution patterns from experimental data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(labelled)
library(reporttools)
library(magrittr)
```
##What other papers do (statistical analysis)
###EK (17): 
- Allocation to Unicef ~ 'productivity' of donating to Other (overall? where is that regression?)
- Total allocation ~  'productivity' Other | split by whether Other is more/less productive than Unicef (where is this table?)
- Difference in mean donation to Unicef when paired with another charity relative to pairing with Global-Child; significance tests (which?) with a mht correction (which?)
- Allocation to Unicef ~  'productivity' Other, vector of controls (sex, age, course) (on/off), treatment dummies (the charity paired), interaction of this with 'productivity Other'; OLS, Tobit robustness check
- Allocation to Unicef~  productivity-other interact with: (individual's perceived similarity of charities, favorability difference, round, etc) (Table 6)
- ... main regressions with control for first-period price
 
###Filiz-Ozbay, N. Uler 

- "Mann-Whitney tests confirm that the donations [to the rebated cause?] increase significantly as the rebate rate increases from 0.3 to 0.5, from 0.5 to 0.7 and from 0.7 to 0.9 (all p-values are less than 0.05)
- total giving increases with the rebate rate in both experiments.
- 

Reinstein (earlier analysis)

Donkers ea



##Background: summary statistics and diagnostics

(Note: much of this discussion is copied from the Pre-analysis plan (PAP); see analysisplan_substn_excerpt_comments.md)

R: suggest following changes: First two paragraphs of the Background I would shift as first paragraph of Main comparison (otherwise I do not see a difference in summary statistics and Main comparisons (edited)
For summary statistics I would just 

We present summary statistics of the donation incidence, levels, and distribution by charity and treatment, as well as key demographics of our population(s) 


```{r Summary statistics}

# Define the categorical variables
varsCat <- AskData %>% ungroup() %>% select(sex, race, relig, single, `uni stdnt`, studies, momjob, dadjob, abroad, CharityTreatf) %>% rename(Gender = sex, Race = race , Religion = relig, Single = single, `University student` = `uni stdnt`, Studies = studies, `Job: Mother` = momjob, `Job: Father`= dadjob, `Stay abroad` = abroad) %>% as.data.frame()  %>%  group_by(CharityTreatf)

nvarsCont <- AskData %>% ungroup() %>% select(siblings, siborder, numchild, CharityTreatf) %>% rename(Siblings = siblings, `Sibling order` = siborder, `Num. of children`= numchild) %>% as.data.frame() %>%  group_by(CharityTreatf)

capCat  <- "Categorical covariates"
capCont <- "Continuous covariates"

# add the group =  option in order to compare between the treatments

RandomizationTableCat <- tableNominal(vars = vanrsCat, cap = capCat, vertical = FALSE, lab = "tab:RandTableCat", longtable = TRUE, booktabs = TRUE, cumsum = FALSE)
# RandomizationTableCat <- tableNominal(vars = varsCat, cap = capCat, vertical = FALSE, lab = "tab:RandTableCat", longtable = TRUE, booktabs = TRUE, cumsum = FALSE)
  
```

*Comments on previous chunk:*

- DR, @GR: We should do variable defining/renaming elsewhere
- The table of majors is painful. I recall I subcategorised these elsewhere; will try to fix (or maybe Anca can do that)

PAP: 
> If the data suggests strong departures from the  linear or exponential models, e.g., bi-modality or sensitivity to outliers,  we may also report specifications  more appropriate to these functional forms, and will make an argument for the suitability of these,  noting this was not central to our initial plan.

We focus these tests on the summary statistics presented above. (Donation levels by charity and treatment, demographics of our population(s))

```{r Diagnostic tests}
TableDonation <- AskData %>% ungroup() %>% drop_na(Donation, CharityTreatf) %>% group_by(CharityTreatf, Stage) %>% dplyr::summarize(count=n(), Donation = mean(Donation, na.rm = F))
TableDonation

TableDonationExeter <- AskDataExeter %>% ungroup() %>% drop_na(Donation, Treatment) %>% group_by(Treatment, Stage) %>% dplyr::summarize(count=n(), Donation = mean(Donation, na.rm = T))
TableDonationExeter

```


*Comments on previous chunk:*
DR, @GR: Let's include some additional  statistical measures (e.g., shares donating, quantiles)  and perhaps a scatterplot.  We should do something like testing for the influence of outliers and testing for "non-normality" or multiple peaks.  Of course, I don't expect the data to be normal as there is censoring/corner solution at the minimum and maximum donation and  perhaps a two-step hurdle ( intensive and extensive margin decisions).  So what would be the equivalent thing to test for?

Also some of this diagnostic testing will have to do with the "impact of the treatment".  Let me try to find some references on this...
  
##Main comparisons

PAP:

> We will perform standard parametric and nonparametric statistical analyses on full relevant samples, as well as testing for differences between subsets mentioned below.  

> As treatments are administered randomly, and by design orthogonally to one another, we will first report statistical test without controls, particularly Fisher's exact test (for categorical outcomes and treatments) and Wilcoxon rank-sum test for continuous outcome variables.

PAP: 

> We will test for differences in the level and incidence of contributions at the *second intervention* (for the nonstudents this is via the Omnibus; for the Students, this is via the employability survey), between:

> 1. 'No ask' vs 'some previous ask'
> 2. 'Previous ask for similar charity' vs 'Previous ask for distinct charity'
> 3. 'Previous ask for similar charity in poverty domain' vs 'Previous ask for similar charity in health domain'
> 4. Recent previous ask (based on time email was sent to participant) versus less recent ask (we will fit a model of 'impact of delay on later contribution')

> For 2-4, we will also test for differences in differences, e.g., we will test whether those who are asked to donate to a similar charity increase or decrease their donations (between the 2 time intervals) more than those asked to donate to a distinct charity.

*Ex post update:*  The nonstudent response was small, and we were required to contact all students simultaneously; thus we have little power to distinguish the 'relative timing' effects.

```{r Statistical tests without controls}
#Fisher's exact test (for categorical outcomes and treatments) 
#Wilcoxon rank-sum test for continuous outcome variables.
#Also "randomization statistical inference"? (Mosaic package or "ri" package?)

bimatrix = matrix(,ncol=2)
fisher.test()


```

```{r Plots}
AskData %>% ungroup() %>% group_by(Stage, CharityTreatf) %>% drop_na(Donation, CharityTreatf) %>% ggplot(aes(x = as.factor(Stage), y = Donation, color = CharityTreatf )) + stat_summary(fun.y=mean, geom="point", shape=18, size=3)

AskDataExeter %>% ungroup() %>% ggplot(aes(x = Stage, y = Donation, color = Treatment)) + stat_summary(fun.y=mean, geom="point", shape=18, size=3)

```

*Comments on previous chunk:*
- DR: connect the lines in graph for 'same treatment'... from "0" for "No-ask treatments" perhaps? (also to address the fact that some are equal and thus overshadowed)
- DR: scale should include 0 (otherwise it's confusing)
- Maybe do also for pooled groups "No-ask --> Ask", "Ask-Ask",  etc?
- Add error bars?


> PAP: Even under randomization, there will typically be an inexact balance in predetermined characteristics across treatments. Thus, regressions controls for predetermined observable characteristics (such as gender or income) can sometimes make estimates more efficient. Thus we report regressions with controls. We will perform model-fitting (e.g., stepwise regression) to determine the most efficient set of predetermined controls. We will run linear and Poisson-exponential regressions for charitable giving outcomes (as these are bounded variables), and also do robustness checks for other popular specifications used for bounded dependent variables, such as Tobit models. Similarly we will also report linear probability models and logit models for binary dependent variables, especially the extensive margin (donated a positive amount to a particular charity).  We are not likely report so-called "conditional on positive" effects, as these are difficult to identify  without an exogenous instrument for the extensive margin decision (we will only do so if such an instrument/shifter  becomes apparent to us in a very obvious way after collecting the data.)


##Regression analysis

Below, we run the 'matrix' of regressions (iterate function?) for

- students, nonstudents, pooled
- s2 donation, total donation, s2 donated,  (and 'deltas?'), 
- pooled/disagreggated treatments, and with/without 'similar charity' interaction and 'controls' for charity type
- linear, Poisson-exponential, (tobit), (quantile?)
- no 'noise-reduction' controls, ad-hoc controls, model-fit controls (Ridge Regression with regularization over noise variables only)

Also:
- ? what to do with S1 donations? (see previous and other papers; endogeneity/mediation an issue)
  - control 
- adding Lee bounds for each? 

- outcome 'donation to charity in s2' with controls for charity type, s1 charity type,  interaction?



```{r Regressions with controls, model fitting}

#e.g., stata:     reg Donation2 DfirstaskDom DfirstaskInt Dsecondaskdom Dbothaskdom Dbothaskint, cluster(code)

reg0 <- lm(AskData$Donation ~ AskData$CharityTreatf)

#summary(lm(fev1_litres ~ ht_cm) )



```

Include estimates incorporating the Lee (2009) bounds [?alt Horowitz and Manski (2000a)?]

> amounts to first identifying the excess number of individuals who are induced to be selected... [in our case an non-attriters] because of the treatment and then “trimming” the upper and lower tails of the outcome ... distribution by this number, yielding a worst-case scenario bound. The assumptions for identifying the bounds are already assumed in conventional models for sample selection: (1) the regressor of interest is independent of the errors in the outcome and selection equations and (2) the selection equation can be written as a standard latent variable binary response model. In the case of an experiment, random assignment ensures that the first assumption holds. It is proven that the trimming procedure yields the tightest bounds for the average treatment effect that are consistent with the observed data. No exclusion restrictions are required, nor is a bounded support for the outcome variable.

Illustrative slides on both of these here: http://economics.ozier.com/econ626/lec/econ626lecture10_slides.pdf

```{r Creating matrix of robustness checks for alternate specifications, inclusion criteria}

```


##Differentiation of estimated effects (heterogeneity, interactions)

PaP: Previous work (Reinstein, 2011; Karlan and Wood 2017, indirectly) suggests a greater degree of substitution (crowding-out) among those who are large and regular givers. ...

Donors who have a personal optimization strategy and target, rather than donors who respond to emotional cues and  powerful appeals,  are also  arguably more likely to exhibit substitution.  Because of this, we will differentiate our estimates by personality attributes (measure in the omnibus) that previous literature find are associated with analytical versus emotional decision-making.

We will estimate all of the above pooling Students and Non-students as our primary object of interest; we will estimate these separately as a secondary descriptive result.

Because giving behavior has been found in many cases to differ by gender and by religious background, we will also bifurcate our estimates by these categories (gender, indicated religious affiliation vs. agnostic/atheist).  We have no ex-ante hypothesis for differences in the substitution effects between these groups.

```{r Regressions-- "honest" differentiation (cross-validated and adjusted for mht), considering nonlinearity}

```


##Mediation analysis (exploratory)

PAP: We will also attempt to measure whether the impact of the first ask on later donations is *mediated* by the donation response to the first ask (e.g., those who *donate* in the first ask may donate less in the second ask, while those who do *not* donate in the first ask may donate more in the second ask) . However, mediation analysis is difficult,  and we will state our results cautiously, following the guidance and techniques suggested in Heckman and Pinto (2014).

```{r Mediation analysis}

```

##Additional results of interest
```{r Additional results of interest}

```

##Ex-post power analyses and other evidentiary considerations


##Meta-analysis (present and prior work, own and other authors)

